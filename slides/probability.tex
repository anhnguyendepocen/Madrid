\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage{palatino}
\usepackage{subfig}
\usepackage{amsmath}
\usepackage{dsfont}
\usepackage{multimedia}

\usetheme{Warsaw}
\usecolortheme{crane}

% www.sharelatex.com/learn/Beamer

\title{Probability and (Bayesian) Data Analysis}
\author{Brendon J. Brewer}
\institute{Department of Statistics\\
The University of Auckland}
\date{{\tt \color{blue} https://www.stat.auckland.ac.nz/\~{ }brewer/}}

\begin{document}

\frame{\titlepage}


% New slide
\begin{frame}
\frametitle{Probability}

Probability is a mathematical framework that has two main applications:
\vspace{0.5em}
\begin{enumerate}
  \item[(1)] Describing proportions of sets.
  \item[(2)] Describing the plausibility of statements.
\end{enumerate}
\vspace{1em}
(1) is associated with `frequentist' statistics, and (2) is `Bayesian'.
Both are valid. The kind of `frequentism' I disagree with is the denial
of (2), not the acceptance of (1).

\end{frame}


% New slide
\begin{frame}
\frametitle{The two rules of probability --- general versions}
For any propositions/statements $X$, $Y$, and $Z$, we have
the {\bf sum rule}:

\begin{align}
P(X \vee Y | Z) = P(X | Z) + P(Y | Z) - P(X, Y | Z)
\end{align}

and the {\bf product rule}:

\begin{align}
P(X, Y | Z) = P(X | Z)P(Y | X, Z).
\end{align}

\end{frame}


% New slide
\begin{frame}
\frametitle{Easier versions}
The easy sum rule:

\begin{align}
P(X \vee Y) = P(X) + P(Y)
\end{align}
when $X$ and $Y$ are mutually exclusive (they cannot both be true, i.e.,
they are two {\em alternative} hypotheses).

The easy product rule:
\begin{align}
P(X, Y) = P(X)P(Y | X).
\end{align}
for any statements $X$, $Y$.

\end{frame}


% New slide
\begin{frame}
\frametitle{Bayes' rule}

From the product rule and commutativity of logical {\em and}:

\begin{align}
P(H|D) &= \frac{P(H)P(D|H)}{P(D)}
\end{align}

\end{frame}


% New slide
\begin{frame}
\frametitle{Special properties}
Sometimes probability assignments make pairs of statements
{\em independent}. In this special case, the product rule reduces to:
\begin{align}
P(X,Y) &= P(X)P(Y)
\end{align}

Sometimes probability assignments make pairs of statements
{\em mutually exclusive}. In this special case, the sum rule reduces to:
\begin{align}
P(X \vee Y) &= P(X) + P(Y).
\end{align}

\end{frame}

% New slide
\begin{frame}
\frametitle{Bayes' rule --- most useful form}
For a set of {\em mutually exclusive and exhaustive} (i.e., they're
{\em alternatives}) hypotheses $\{H_i\}$,

\begin{align}
P(H_i|D) &= \frac{P(H_i)P(D|H_i)}{\sum_i P(H_i)P(D|H_i)}.
\end{align}

\begin{itemize}
\item $P(H_i)$ are the prior probabilities
\item $P(D|H_i)$ are the likelihoods
\item The denominator, $P(D)$ is the `marginal likelihood' or `evidence'.
\end{itemize}

\end{frame}

% New slide
\begin{frame}
\frametitle{Basic Bayesian exercises}

Do exercise set 1.

\end{frame}



\end{document}


